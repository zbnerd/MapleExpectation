# ADR-053: Observability Stack (Prometheus + Grafana + Loki + OpenTelemetry)

## 제1장: 문제의 발견 (Problem)

**분산 시스템에서의 디버깅 어려움**

MapleExpectation은 Spring Boot 기반 분산 시스템으로, Redis 분산 캐시, MySQL Replication, 다중 인스턴스 Scale-out 아키텍처를 운영 중입니다. 1,000+ 동시 사용자 환경에서 다음 문제들이 발생했습니다.

1. **로그 집계 부재**: 파일 로그만으로는 인스턴스 간 분산된 이벤트 추적이 불가능
2. **메트릭 시각화 부족**: Performance Bottleneck 식별을 위한 실시간 지표 부족
3. **알림 시스템 미비**: 장애 발생 시 운영팀 인지 지연
4. **분산 추적 미지원**: 마이크로서비스 간 호출 흐름 추적 불가

**구체적 발생 사례**

| 문제 | 영향 |
|------|------|
| MySQL Slow Query 로그 분석 어려움 | 쿼리 튜닝 지연 |
| 캐시 히트율 모니터링 부족 | Cache Stampade 미탐지 |
| 서킷브레이커 상태 모니터링 부족 | 장애 전파 즉시 대응 불가 |
| 장애 원인 파악 지연 | MTTR(Mean Time To Recovery) 증가 |

---

## 제2장: 선택지 탐색 (Options)

### 선택지 1: ELK Stack (Elasticsearch, Logstash, Kibana)

**장점:**
- 강력한 전문 검색 엔진
- 풍부한 시각화 기능
- 대규모 로그 처리 최적화

**단점:**
- 리소스 소모 큼 (Elasticsearch 최소 4GB RAM)
- 운영 복잡도 높음 (Cluster 구성, Sharding, Rebalancing)
- 라이선스 비용 발생 (상용 기능)

### 선택지 2: AWS CloudWatch

**장점:**
- AWS 네이티브 통합
- 설정 간편
- 자동 확장

**단점:**
- Vendor Lock-in (AWS 종속)
- 쿼리 비용 발생 (CloudWatch Insights)
- 로그 보관 비용 상승

### 선택지 3: Datadog

**장점:**
- APM, Log, Metrics 통합 플랫폼
- 자동 계측 (Auto-instrumentation)
- 강력한 Alerting

**단점:**
- 비용 매우 높음 (Host당 $15+/month)
- Scale-out 시 비용 급증
- Custom Dashboard 제약

### 선택지 4: Prometheus + Grafana + Loki (채택)

**장점:**
- 완전한 Open Source
- 경량화 (Loki: <500MB RAM)
- Grafana 강력한 대시보드
- Prometheus 표준 (Metrics 수집)
- OpenTelemetry 표준 준수 (Tracing)
- Prometheus Alertmanager (Alert Routing)

**단점:**
-运维 복잡도 (다중 컨테이너 관리)
- Retention Storage 필요
- Alert Rule Tuning 필요

### 선택지 5: Jaeger (Tracing Only)

**장점:**
- 분산 추적 전문
- OpenTelemetry 호환

**단점:**
- Log/Metrics 별도 솔루션 필요
- 통합 관리 포인트 증가

---

## 제3장: 결정의 근거 (Decision)

**채택: Prometheus + Grafana + Loki + OpenTelemetry**

**결정 배경:**

1. **비용 효율성**: 완전한 Open Source로 무료
2. **경량화**: Loki 512MB, Prometheus 512MB, Grafana 256MB로 AWS t3.small 운영 가능
3. **표준 준수**: Prometheus (Metrics), OpenTelemetry (Tracing), Loki (Logs)
4. **통합 관리**: Grafana 단일 대시보드에서 Logs/Metrics/Traces 통합 조회
5. **Alertmanager**: 유연한 Alert Routing (Email, Slack, Webhook)
6. **Promtail**: MySQL Slow Query 로그 수집 및 파싱

**배제 대안:**

| 대안 | 배제 사유 |
|------|----------|
| ELK Stack | 리소스 과다, 운영 복잡도 |
| CloudWatch | Vendor Lock-in, 비용 |
| Datadog | 비용 ($1000+/month @ 1000 사용자) |
| Jaeger Only | Logs/Metrics 별도 솔루션 필요 |

---

## 제4장: 구현의 여정 (Action)

### 4.1 Docker Compose 전체 스택 구성

**파일**: `/home/maple/MapleExpectation/docker-compose.observability.yml`

```yaml
services:
  # Loki: 로그 수집 및 저장 (2.9.0)
  loki:
    image: grafana/loki:2.9.0
    ports: ["3100:3100"]
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Prometheus: 메트릭 수집
  prometheus:
    image: prom/prometheus:latest
    ports: ["9090:9090"]
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=15d'
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro

  # Grafana: 대시보드 및 시각화 (10.2.0)
  grafana:
    image: grafana/grafana:10.2.0
    ports: ["3000:3000"]
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}

  # Alertmanager: Alert Routing
  alertmanager:
    image: prom/alertmanager:latest
    ports: ["9093:9093"]
    volumes:
      - ./docker/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro

  # Promtail: MySQL Slow Query 로그 수집
  promtail:
    image: grafana/promtail:2.9.0
    volumes:
      - ./docker/promtail-config/config.yml:/etc/promtail/config.yml:ro
      - ./docker/logs/mysql:/var/log/mysql:ro
```

### 4.2 Prometheus 설정

**파일**: `/home/maple/MapleExpectation/docker/prometheus/prometheus.yml`

```yaml
scrape_configs:
  # Maple Expectation Application
  - job_name: 'maple-expectation'
    scrape_interval: 5s
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['host.docker.internal:8080']
        labels:
          application: 'maple-expectation'
          environment: '${ENVIRONMENT:local}'

  # Node Exporter - System Metrics
  - job_name: 'node-exporter'
    scrape_interval: 15s
    static_configs:
      - targets: ['node-exporter:9100']

  # Resilience4j Metrics
  - job_name: 'resilience4j'
    scrape_interval: 5s
    metrics_path: '/actuator/resilience4j'
    static_configs:
      - targets: ['host.docker.internal:8080']
```

### 4.3 Alertmanager 설정

**파일**: `/home/maple/MapleExpectation/docker/alertmanager/alertmanager.yml`

```yaml
route:
  group_by: ['alertname', 'severity', 'category']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

  routes:
    # Critical alerts
    - match:
        severity: critical
      receiver: 'critical-alerts'
      continue: true

    # Warning alerts
    - match:
        severity: warning
      receiver: 'warning-alerts'

receivers:
  - name: 'critical-alerts'
    email_configs:
      - to: 'admin@maple-expectation.com'
        subject: 'CRITICAL ALERT: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        title: 'CRITICAL ALERT'
```

### 4.4 Promtail MySQL Slow Query 파싱

**파일**: `/home/maple/MapleExpectation/docker/promtail-config/config.yml`

```yaml
scrape_configs:
  - job_name: mysql_slow_query
    static_configs:
      - targets: ['localhost']
        labels:
          job: slow-query
          __path__: /var/log/mysql/slow.log
    pipeline_stages:
      # Multiline 처리
      - multiline:
          firstline: '^# Time:'
          max_wait_time: 3s

      # Query Time 추출
      - regex:
          expression: 'Query_time:\s+(?P<query_time>[\d.]+)\s+Lock_time:\s+(?P<lock_time>[\d.]+)'

      # 라벨 추가
      - labels:
          query_time:
          lock_time:
```

### 4.5 Gradle 의존성 구성

**파일**: `/home/maple/MapleExpectation/module-app/build.gradle`

```groovy
dependencies {
    // Actuator & Observability
    implementation 'org.springframework.boot:spring-boot-starter-actuator'
    implementation 'io.micrometer:micrometer-observation'
    implementation 'io.micrometer:micrometer-registry-prometheus'
    implementation 'io.micrometer:micrometer-tracing-bridge-otel'
    implementation 'io.opentelemetry:opentelemetry-exporter-otlp'
    implementation 'io.opentelemetry.contrib:opentelemetry-samplers:1.33.0-alpha'

    // Loki Appender
    implementation 'com.github.loki4j:loki-logback-appender:1.4.2'
}
```

### 4.6 Application 설정

**파일**: `/home/maple/MapleExpectation/module-app/src/main/resources/application.yml`

```yaml
management:
  endpoints:
    web:
      exposure:
        include: "health,info,metrics,prometheus,loggers"
    enabled-by-default: true

  endpoint:
    prometheus:
      enabled: true
    metrics:
      enabled: true

  metrics:
    tags:
      application: ${spring.application.name}
    export:
      prometheus:
        enabled: true
    distribution:
      percentiles-histogram:
        http.server.requests: [0.5, 0.95, 0.99]

  # OpenTelemetry tracing 설정
  tracing:
    enabled: ${OTEL_ENABLED:false}
    sampling:
      probability: 0.05  # 5% Head Sampling

observability:
  loki:
    url: ${LOKI_URL:http://localhost:3100}

otel:
  exporter:
    otlp:
      endpoint: ${OTEL_EXPORTER_OTLP_ENDPOINT:http://localhost:4318}
      protocol: http/protobuf
```

### 4.7 Logback Loki Appender

**파일**: `/home/maple/MapleExpectation/module-app/src/main/resources/logback-spring.xml`

```xml
<springProfile name="prod">
    <appender name="LOKI" class="com.github.loki4j.logback.Loki4jAppender">
        <http>
            <url>${LOKI_URL:-http://localhost:3100}/loki/api/v1/push</url>
            <connectionTimeoutMs>5000</connectionTimeoutMs>
            <requestTimeoutMs>10000</requestTimeoutMs>
        </http>
        <format class="com.github.loki4j.logback.JsonEncoder">
            <label>
                <pattern>app=maple-expectation,env=${ENV:-prod},host=${HOSTNAME:-unknown}</pattern>
            </label>
        </format>
    </appender>

    <appender name="LOKI_ASYNC" class="ch.qos.logback.classic.AsyncAppender">
        <queueSize>8192</queueSize>
        <discardingThreshold>0</discardingThreshold>
        <neverBlock>true</neverBlock>
        <appender-ref ref="LOKI" />
    </appender>

    <root level="INFO">
        <appender-ref ref="CONSOLE" />
        <appender-ref ref="LOKI_ASYNC" />
    </root>
</springProfile>
```

---

## 제5장: 결과와 학습 (Result)

### 5.1 현재 상태

| 컴포넌트 | 상태 | 용도 |
|----------|------|------|
| **Loki 2.9.0** | 활성 | 로그 집계 (전체 로그) |
| **Prometheus** | 활성 | 메트릭 수집 (Actuator/Prometheus) |
| **Grafana 10.2.0** | 활성 | 대시보드 시각화 |
| **Alertmanager** | 활성 | 알림 라우팅 (Email/Slack/Webhook) |
| **Promtail 2.9.0** | 활성 | MySQL Slow Query 파싱 |
| **OpenTelemetry** | 선택적 | 분산 추적 (prod에서 활성화) |

### 5.2 잘 된 점

1. **비용 절감**: Datadog 대비 월 $1000+ 비용 절감
2. **경량화**: 전체 스택 < 2GB RAM (AWS t3.small 운영 가능)
3. **MySQL Slow Query 시각화**: Promtail 파싱으로 Query Time/lock_time 추출
4. **통합 관리**: Grafana에서 Logs/Metrics/Traces 단일 창 조회
5. **유연한 Alerting**: Alertmanager로 Severity별 라우팅 (Critical/Warning/Info)
6. **표준 준수**: Prometheus + OpenTelemetry로 벤더 중립성 확보

### 5.3 아쉬운 점

1. **运维 복잡도**: 6개 컨테이너 관리 (Loki, Prometheus, Grafana, Alertmanager, Promtail, Node Exporter)
2. **Retention Storage**: 15일 보관 시 약 10GB 필요 (S3/Glacier 아카이빙 미구현)
3. **Alert Rule Tuning**: False Positive 줄이기 위한 임계값 조정 필요
4. **Head Sampling 한계**: 5% Sampling으로 단일 요청 추적 누락 가능성
5. **Loki 쿼리 학습곡선**: LogQL(Log Query Language) 숙련 필요

### 5.4 개선 방향

| 개선 항목 | 계획 | 우선순위 |
|----------|------|----------|
| S3/Glacier 아카이빙 | 오래된 로그 장기 보관 | P1 |
| Dynamic Alert Rule | 머신러닝 기반 임계값 자동 조정 | P2 |
| Jaeger 통합 | 완전한 Distributed Tracing | P2 |
| Loki 쿼리 템플릿 | 자주 쓰는 쿼리 자동화 | P1 |
| Alert Inhibition Rule | 중복 알림 제어 | P1 |

### 5.5 운영 가이드

**시작 명령어:**
```bash
docker-compose -f docker-compose.observability.yml up -d
```

**접속 경로:**
- Grafana: http://localhost:3000 (환경변수 `GRAFANA_ADMIN_USER`, `GRAFANA_ADMIN_PASSWORD` 필요)
- Prometheus: http://localhost:9090
- Loki API: http://localhost:3100
- Alertmanager: http://localhost:9093

---

## 관련 결정

- **ADR-006**: Redis Lock & Watchdog (Cache Monitoring 필요)
- **ADR-007**: AOP Async Cache Integration (Distributed Tracing 필요)
- **ADR-017**: Spring Batch Integration (Batch Job Monitoring)

## 관련 문서

- **Infrastructure Guide**: [docs/03_Technical_Guides/infrastructure.md](../03_Technical_Guides/infrastructure.md) - Section 9: Observability & Validation
- **Chaos Engineering**: [docs/02_Chaos_Engineering/](../02_Chaos_Engineering/) - N01-N18 시나리오 모니터링

## 증거 링크

- **Docker Compose**: [docker-compose.observability.yml](../../docker-compose.observability.yml)
- **Prometheus Config**: [docker/prometheus/prometheus.yml](../../docker/prometheus/prometheus.yml)
- **Alertmanager Config**: [docker/alertmanager/alertmanager.yml](../../docker/alertmanager/alertmanager.yml)
- **Promtail Config**: [docker/promtail-config/config.yml](../../docker/promtail-config/config.yml)
- **Logback Config**: [module-app/src/main/resources/logback-spring.xml](../../module-app/src/main/resources/logback-spring.xml)
- **Application YAML**: [module-app/src/main/resources/application.yml](../../module-app/src/main/resources/application.yml)
- **Gradle Dependencies**: [module-app/build.gradle](../../module-app/build.gradle) (lines 58-70)

---

**ADR 상태**: Accepted (2026-02-19)

**검토자**: 5-Agent Council (Blue: Observability, Green: Performance, Yellow: Reliability, Purple: Security, Red: Scalability)
