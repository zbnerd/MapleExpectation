# ADR-046: Transactional Outbox 패턴과 Triple Safety Net

## 제1장: 문제의 발견 (Problem)

### P0 #287: Compensation 실패로 247개 사용자 좋아요 손실

2025년 12월, 메시지 큐와 비즈니스 트랜잭션의 원자성 보장 실패로 데이터 유실이 발생했습니다.

**구체적인 문제 상황:**
1. **분산 환경 경합**: Redis 버퍼에서 데이터를 원자적으로 가져와 DB에 저장하는 과정에서 경합 발생
2. **보상 트랜잭션 실패**: DB 저장 실패 시 Redis 버퍼 복원(compensate)이 실패하면 데이터가 영구 손실
3. **외부 API 장애**: Nexon API 6시간 장애 시 재시도 메커니즘 부재로 누적 이벤트 처리 불가

**왜 결정이 필요했는가?**
- 금융수준 데이터 무결성 요구 (유실 허용치: 0건)
- Scale-out 환경에서의 원자적 연산 보장 필요
- 장애 복구 자동화로 운영 부하 최소화

---

## 제2장: 선택지 탐색 (Options)

### 대안 1: 직접 API 호출 (Synchronous)

**구조:**
```java
// 버퍼에서 직접 꺼내서 API 호출
List<LikeData> pending = buffer.getPending();
for (LikeData data : pending) {
    nexonApi.call(data);  // 실패 시 데이터 유실
}
```

**장점:**
- 구현 단순
- 레이턴시 낮음

**단점:**
- **지속성 없음**: API 실패 시 즉시 유실 (P0 #287 발생 경로)
- 재시도 로직 중복 구현 필요
- 장애 윈도우 동안 데이터 보존 불가

---

### 대안 2: 단순 Event Queue (Redis List)

**구조:**
```java
// Redis LPUSH/RPOP 패턴
redis.lpush("event:queue", eventData);
String event = redis.rpop("event:queue");
nexonApi.call(event);
```

**장점:**
- FIFO 보장
- 분산 환경 지원

**단점:**
- **트랜잭션 보장 없음**: RPOP 후 API 실패 시 데이터 유실
- DB 트랜잭션과 연동 불가
- 재시도 전략 별도 구현 필요

---

### 대안 3: Event Sourcing with Append-Only Log

**구조:**
```java
// 불변 이벤트 로그
eventStore.append(new LikeEvent(ocid, targetOid));
eventReplayer.replayAll();  // 전체 로그 재생
```

**장점:**
- 완전한 감사 추적 (Audit Trail)
- 시간 여행 가능 (Temporal Query)

**단점:**
- 복잡도 과도 (현재 요구사항 대비)
- 스냅샷 관리 오버헤드
- 쿼리 성능 저하 (전체 로그 스캔)

---

### 대안 4: Transactional Outbox Pattern (채택)

**구조:**
```java
// 1. 비즈니스 변경 + Outbox 기록을 동일 트랜잭션으로
@Transactional
public void processLike(LikeRequest request) {
    updateDatabase(request);              // 비즈니스 상태 변경
    outboxRepository.save(new OutboxEntry(request)); // 같은 트랜잭션
}

// 2. 별도 프로세스가 Outbox를 읽어서 API 호출
@Scheduled(fixedRate = 30000)
public void pollAndProcess() {
    List<OutboxEntry> pending = outboxRepository.findPendingWithLock();
    pending.forEach(entry -> nexonApi.call(entry));
}
```

**장점:**
- **원자성 보장**: Business change + message를 같은 DB 트랜잭션으로 기록
- **지속성**: DB에 영구 저장 (JVM 크래시 안전)
- **자동 복구**: Scheduler가 자동으로 재시도
- **분산 안전성**: SKIP LOCKED로 중복 처리 방지

**단점:**
- 약간의 레이턴시 (폴링 주기 30초)
- Outbox 테이블 관리 오버헤드
- Lua Script와 Hash Tag로 Redis Cluster 호환성 확보 필요

---

## 제3장: 결정의 근거 (Decision)

### 선택: Transactional Outbox Pattern + Triple Safety Net

**채택 이유:**

1. **원자성 보장 (Critical)**
   - DB 트랜잭션으로 비즈니스 상태와 Outbox 기록을 원자적으로 커밋
   - "All or Nothing" 보장: 둘 다 성공하거나 둘 다 실패

2. **Triple Safety Net으로 다중 방어**
   - **1차**: Lua Script로 원자적 fetch (RENAME + EXPIRE + HGETALL in single operation)
   - **2차**: Compensation Transaction으로 복원 실패 시 recover
   - **3차**: DLQ (Dead Letter Queue)로 최후 데이터 보존

3. **Redis Cluster 호환성**
   - Hash Tag `{buffer:likes}`로 동일 슬롯 보장
   - Lua Script에서 다중 키 연산 가능

4. **운영 자동화**
   - 47분 만에 216만 건 자동 복구 (N19 Recovery Report)
   - 수동 개입 없이 99.98% 성공

**트레이드오프 분석:**

| 측면 | 채택 안 | 대안 1 (직접 호출) | 대안 2 (단순 큐) | 대안 3 (Event Sourcing) |
|------|--------|-------------------|-----------------|------------------------|
| 데이터 유실 방지 | ✅ 완벽 | ❌ 불가 | ⚠️ 부분 | ✅ 완벽 |
| 복잡도 | 중간 | 낮음 | 낮음 | 높음 |
| 운영 오버헤드 | 최소 | 높음 (수동) | 중간 | 높음 |
| 자동 복구 | ✅ 가능 | ❌ 불가 | ⚠️ 별도 구현 | ⚠️ 복잡 |
| Scale-out 호환 | ✅ 완벽 | ✅ 가능 | ✅ 가능 | ✅ 가능 |

---

## 제4장: 구현의 여정 (Action)

### 4.1 Redis Lua Script 원자적 연산

**증거 파일:** `/home/maple/MapleExpectation/docs/03_Technical_Guides/infrastructure.md` (Section 8-1)

**구현 코드 패턴:**
```java
// /home/maple/MapleExpectation/src/main/java/global/strategy/RedisAtomicFetchStrategy.java

private static final String LUA_ATOMIC_MOVE = """
        local exists = redis.call('EXISTS', KEYS[1])
        if exists == 0 then return {} end
        redis.call('RENAME', KEYS[1], KEYS[2])
        redis.call('EXPIRE', KEYS[2], ARGV[1])
        return redis.call('HGETALL', KEYS[2])
        """;

public FetchResult fetchAndMove(String sourceKey, String tempKey) {
    RScript script = redissonClient.getScript(StringCodec.INSTANCE);
    List<Object> result = script.eval(
            RScript.Mode.READ_WRITE,
            LUA_ATOMIC_MOVE,
            RScript.ReturnType.MULTI,
            Arrays.asList(sourceKey, tempKey),
            String.valueOf(ttlSeconds)
    );
    return FetchResult.fromRedisResult(result);
}
```

**핵심 포인트:**
- `RENAME`: 원본 키를 임시 키로 원자적 이동 (다른 클라이언트가 가져가지 못함)
- `EXPIRE`: 임시 키 TTL 설정 (JVM 크래시 시 메모리 누수 방지)
- `HGETALL`: 모든 해시 필드 반환 (단일 네트워크 왕복)

---

### 4.2 Redis Cluster Hash Tag 규칙

**증거 파일:** `/home/maple/MapleExpectation/docs/03_Technical_Guides/infrastructure.md` (Section 8-1)

**구현 코드:**
```java
// /home/maple/MapleExpectation/src/main/java/service/v2/worker/LikeBufferWorker.java

public static final String SOURCE_KEY = "{buffer:likes}";
private static final String TEMP_KEY_PREFIX = "{buffer:likes}:sync:";

public void processBatch() {
    String tempKey = TEMP_KEY_PREFIX + UUID.randomUUID();
    // Hash Tag로 같은 슬롯 보장
    FetchResult result = fetchStrategy.fetchAndMove(SOURCE_KEY, tempKey);
    saveToDatabase(result);
}
```

**Hash Tag 동작 원리:**
```
# Bad (다른 해시값 -> Cluster에서 CROSSSLOT Error)
"buffer:likes"       → hash_slot_1234
"buffer:likes:sync"  → hash_slot_5678

# Good (Hash Tag -> 같은 슬롯)
"{buffer:likes}"           → hash_slot("{buffer:likes}") = 1234
"{buffer:likes}:sync:uuid" → hash_slot("{buffer:likes}") = 1234
```

---

### 4.3 보상 트랜잭션 (Compensation Transaction)

**증거 파일:** `/home/maple/MapleExpectation/docs/03_Technical_Guides/infrastructure.md` (Section 8-1)

**구현 코드:**
```java
// /home/maple/MapleExpectation/src/main/java/global/command/RedisCompensationCommand.java

public record RedisCompensationCommand(
        String sourceKey,
        String tempKey,
        FetchResult fetchResult,
        RedisAtomicFetchStrategy strategy,
        CheckedLogicExecutor executor
) implements CompensationCommand {

    @Override
    public void save(FetchResult result) {
        this.result = result;  // 상태 저장
    }

    @Override
    public void compensate() {
        executor.executeVoid(
                () -> strategy.restore(tempKey, sourceKey),
                TaskContext.of("Compensation", "restore", tempKey)
        );
    }

    @Override
    public void commit() {
        executor.executeVoid(
                () -> strategy.deleteTempKey(tempKey),
                TaskContext.of("Compensation", "commit", tempKey)
        );
    }
}
```

**사용 패턴 (executeWithFinally):**
```java
// /home/maple/MapleExpectation/src/main/java/service/v2/worker/LikeBufferWorker.java

CompensationCommand cmd = new RedisCompensationCommand(sourceKey, tempKey, strategy, executor);
executor.executeWithFinally(
        () -> {
            FetchResult result = strategy.fetchAndMove(sourceKey, tempKey);
            cmd.save(result);
            processDatabase(result);  // DB 저장
            cmd.commit();             // 성공 -> 임시 키 삭제
            return null;
        },
        () -> {
            if (cmd.isPending()) {
                cmd.compensate();     // 실패 -> 원본 키 복원
            }
        },
        context
);
```

---

### 4.4 Triple Safety Net: DLQ (Dead Letter Queue)

**증거 파일:** `/home/maple/MapleExpectation/docs/03_Technical_Guides/infrastructure.md` (Section 8-1)

**P0 #287 해결: Compensation 실패 시 DLQ 이벤트 발행**

```java
// /home/maple/MapleExpectation/src/main/java/global/command/RedisCompensationCommand.java

private void compensate() {
    executor.executeOrCatch(
            () -> strategy.restore(tempKey, sourceKey),
            e -> {
                // P0 FIX: 복구 실패 시 DLQ 이벤트 발행
                LikeSyncFailedEvent event = LikeSyncFailedEvent.fromFetchResult(result, sourceKey, e);
                eventPublisher.publishEvent(event);
                return null;
            },
            context
    );
}

// /home/maple/MapleExpectation/src/main/java/monitoring/listener/LikeSyncEventListener.java

@Async
@EventListener
public void handleSyncFailure(LikeSyncFailedEvent event) {
    // 1. 파일 백업 (데이터 보존 최우선)
    persistenceService.appendLikeEntry(event.userIgn(), event.lostCount());
    // 2. 메트릭 기록
    meterRegistry.counter("like.sync.dlq.triggered").increment();
    // 3. Discord 알림 (운영팀 인지)
    discordAlertService.sendCriticalAlert("DLQ 발생", event.errorMessage());
}
```

**DLQ 처리 우선순위:**
1. **파일 백업** (데이터 보존 최우선)
2. **메트릭 기록** (모니터링)
3. **알림 발송** (운영팀 인지)

---

### 4.5 Orphan Key Recovery (JVM 크래시 대응)

**증거 파일:** `/home/maple/MapleExpectation/docs/03_Technical_Guides/infrastructure.md` (Section 8-1)

```java
// /home/maple/MapleExpectation/src/main/java/config/BufferRecoveryConfig.java

@PostConstruct
public void recoverOrphanKeys() {
    RKeys keys = redissonClient.getKeys();
    Iterable<String> orphans = keys.getKeysByPattern("{buffer:likes}:sync:*");

    for (String orphanKey : orphans) {
        // 임시 키 -> 원본 키로 복원
        atomicFetchStrategy.restore(orphanKey, SOURCE_KEY);
        log.info("Orphan key recovered: {}", orphanKey);
    }
}
```

**임시 키 TTL 안전장치:**
```java
// Lua Script에서 1시간 TTL 설정
redis.call('EXPIRE', KEYS[2], 3600)  // 1시간 후 자동 삭제

// application.yml 설정화
like:
  sync:
    temp-key-ttl-seconds: 3600  # 1시간
```

---

## 제5장: 결과와 학습 (Result)

### 5.1 N19 Recovery Report: 2.1M Event 47분 처리

**증거 파일:** `/home/maple/MapleExpectation/docs/05_Reports/04_07_Recovery/RECOVERY_REPORT_N19_OUTBOX_REPLAY.md`

**인시던트 개요:**
- 2026-02-05, 외부 API 6시간 장애로 216만 건 이벤트 큐잉
- 자동 복구 메커니즘이 47분 만에 99.98% 성공률로 처리
- 데이터 유실 0건

**핵심 성과:**
| 메트릭 | 값 | 목표 | 상태 |
|--------|-------|--------|---------|
| Outbox 항목 수 | 2,160,000건 | - | 초과 |
| 재처리 처리량 | 1,200 TPS | ≥1,000 TPS | ✅ 초과 달성 |
| 자동 복구율 | 99.98% | ≥99.9% | ✅ 초과 달성 |
| DLQ 전환율 | 0.003% | <0.1% | ✅ 목표 달성 |
| 데이터 유실 | **0건** | 0 | ✅ 목표 달성 |
| 복구 시간 | 47분 | <60분 | ✅ 목표 달성 |

**처리 현황 상세:**
| 항목 | 건수 | 비율 |
|------|------|------|
| 성공 처리 | 2,159,948 | 99.98% |
| DLQ 이동 | 52 | 0.002% |
| **총계** | **2,160,000** | **100%** |

---

### 5.2 Reconciliation 불변식 검증

**불변식 (Invariant):**
```
expected_events = processed_success + dlq_events + ignored_duplicates
```

**검증 결과:**
```sql
SELECT
  e.expected_events,
  p.processed_success,
  d.dlq_events,
  (p.processed_success + d.dlq_events) AS accounted_total,
  (e.expected_events - (p.processed_success + d.dlq_events)) AS mismatch
FROM
  (SELECT COUNT(*) AS expected_events FROM nexon_api_outbox
   WHERE created_at >= '2026-02-05 14:00:00') e,
  (SELECT COUNT(*) AS processed_success FROM nexon_api_outbox
   WHERE status = 'COMPLETED' AND updated_at >= '2026-02-05 20:00:00') p,
  (SELECT COUNT(*) AS dlq_events FROM nexon_api_outbox
   WHERE status = 'DEAD_LETTER' AND updated_at >= '2026-02-05 20:00:00') d;
```

**검증 결과:**
- expected_events: 2,160,000
- processed_success: 2,159,948
- dlq_events: 52
- **mismatch: 0** ✅

---

### 5.3 잘 된 점 (Success Factors)

1. **원자성 보장**
   - Lua Script로 RENAME + EXPIRE + HGETALL을 단일 연산으로 수행
   - Redis Cluster에서 Hash Tag로 동일 슬롯 보장

2. **Triple Safety Net**
   - 1차: Lua Script 원자적 fetch
   - 2차: Compensation Transaction 복원
   - 3차: DLQ 파일 백업

3. **분산 안전성**
   - SKIP LOCKED로 다중 인스턴스 중복 처리 방지
   - Orphan Key Recovery로 JVM 크래시 대응

4. **운영 자동화**
   - 수동 개입 없이 99.98% 자동 복구
   - 47분 만에 216만 건 처리

---

### 5.4 아쉬운 점 (Trade-offs)

1. **Lua Script 복잡도**
   - Redis Cluster slot 요구사항으로 Hash Tag 필수 적용
   - 스크립트 디버깅 난이도 증가

2. **JVM Crash 복구 필요**
   - Orphan Key Recovery 로직 추가 구현 필요
   - 시작 시 잠시 지연 발생

3. **DLQ 수동 개입**
   - Compensation 실패 시 DLQ로 이동하지만 수동 복구 필요
   - 파일 백업 후 분석 프로세스 요구

4. **약간의 레이턴시**
   - 30초 폴링 주기로 실시간성 희생
   - 허용 가능한 트레이드오프로 판단

---

### 5.5 적용 범위 및 제언

**적용 대상:**
- ✅ 외부 API 호출 (Nexon Open API)
- ✅ 분산 버퍼 동기화 (Like Buffer)
- ✅ 이벤트 발행 워커 (Event Publisher)

**제언:**
- **Scale-out 환경**: SKIP LOCKED와 Hash Tag로 분산 안전성 보장
- **금융수준 무결성**: Triple Safety Net으로 데이터 유실 방지
- **운영 효율성**: 자동 복구로 MTTD/MTTR 최소화

---

## 참고 문헌

1. **ADR-007**: Redis Lua Script & Hash Tag
2. **N19 Recovery Report**: `/home/maple/MapleExpectation/docs/05_Reports/04_07_Recovery/RECOVERY_REPORT_N19_OUTBOX_REPLAY.md`
3. **Infrastructure Guide**: `/home/maple/MapleExpectation/docs/03_Technical_Guides/infrastructure.md` (Sections 8, 8-1)

---

**ADR 작성일**: 2026-02-19
**상태**: Accepted
**관련 이슈**: P0 #287 (해결 완료), N19 (검증 완료)
