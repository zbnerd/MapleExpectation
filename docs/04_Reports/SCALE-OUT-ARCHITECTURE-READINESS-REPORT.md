# Scale-Out Architecture Readiness Report

> **Analysis Date:** 2026-02-16
> **Analysis Scope:** Full codebase scale-out readiness assessment
> **Target Deployment:** N-instance horizontal scaling (1 â†’ N)
> **Status:** âš ï¸ **CONDITIONAL READY** - Critical blockers identified

---

## Executive Summary

MapleExpectation demonstrates **strong architectural foundations** for scale-out with Redis-based distributed coordination, virtual thread adoption, and proper connection pooling. However, **8 P0 critical blockers** prevent immediate horizontal scaling from 1 to N instances without data integrity risks.

### Overall Assessment

| Category | Status | Score | Details |
|----------|--------|-------|---------|
| **Stateless Design** | âš ï¸ WARNING | 6/10 | 22 stateful components identified |
| **Distributed Coordination** | âœ… GOOD | 8/10 | Redis locks/stream implemented |
| **Thread Pool Sizing** | âœ… EXCELLENT | 9/10 | Virtual threads + proper backpressure |
| **Connection Pooling** | âœ… GOOD | 8/10 | HikariCP + Redisson properly configured |
| **Session Management** | âœ… EXCELLENT | 10/10 | JWT stateless tokens |
| **Graceful Shutdown** | âš ï¸ WARNING | 7/10 | Instance-local shutdown coordination |

### Recommendation

**Current State:** Single-instance production deployment safe
**Scale-Out Readiness:** Requires P0 blocker resolution
**Estimated Effort:** 3-4 weeks (3 sprints) for full N-instance readiness

---

## 1. Stateless Design Analysis

### 1.1 âœ… PASS: No Server-Side Sessions

**Evidence:**
```java
// No HttpSession usage detected
// JWT-based stateless authentication confirmed
grep -r "HttpSession" src/main/java/ | wc -l
# Output: 0
```

**Status:** âœ… **READY FOR SCALE-OUT**

**Details:**
- JWT stateless tokens for authentication
- No session replication required
- Load balancer can route requests to any instance

---

### 1.2 âš ï¸ WARNING: In-Memory State Components

**Total Identified:** 22 stateful components (8 P0 + 14 P1)

#### P0 CRITICAL BLOCKERS (Must Fix Before Scale-Out)

| # | Component | File | Impact | Fix Required |
|---|-----------|------|--------|--------------|
| **P0-1** | AlertThrottler | `monitoring/throttle/AlertThrottler.java:33` | AI quota doubles with N instances | Redis AtomicLong |
| **P0-2** | InMemoryBufferStrategy | `infrastructure/queue/strategy/InMemoryBufferStrategy.java:57` | Data loss on deployment | Already migrated to Redis (feature flag) |
| **P0-3** | LikeBufferStorage | `service/v2/cache/LikeBufferStorage.java:35` | Count inconsistency | Redis distributed buffer |
| **P0-4** | SingleFlightExecutor | `infrastructure/concurrency/SingleFlightExecutor.java:52` | Duplicate API calls (NÃ— load) | Redis distributed single-flight |
| **P0-5** | AiSreService | `monitoring/ai/AiSreService.java:65` | Unbounded virtual threads â†’ OOM | Bean + semaphore limiting |
| **P0-6** | LoggingAspect | `aop/aspect/LoggingAspect.java:30` | Instance-local lifecycle | Redis shutdown flag |
| **P0-7** | CompensationLogService | `infrastructure/resilience/CompensationLogService.java:64` | Consumer group duplication | Unique consumerId |
| **P0-8** | DynamicTTLManager | `infrastructure/resilience/DynamicTTLManager.java:80` | Event duplication | Centralized state |

**Impact Summary:**

```
Single Instance (Current):
âœ… AlertThrottler.dailyAiCallCount = 50/day (correct)
âœ… Single-flight prevents duplicate API calls
âœ… AiSreService unbounded (controlled by low traffic)

N Instances (Without Fixes):
âŒ AlertThrottler.dailyAiCallCount = 50 Ã— N (quota breach)
âŒ Single-flight bypassed â†’ API load Ã— N
âŒ AiSreService unbounded Ã— N â†’ OOM risk
```

**Fix Priority:** P0 blockers must be resolved before scale-out deployment.

---

#### P1 HIGH PRIORITY (Data Consistency Risks)

| # | Component | File | Impact | Fix Required |
|---|-----------|------|--------|--------------|
| **P1-1** | RateLimiter | `infrastructure/ratelimit/strategy/*` | Rate limit Ã— N instances | Bucket4j distributed config |
| **P1-4** | LikeBufferConfig | `config/LikeBufferConfig.java:59` | Feature flag defaults to In-Memory | matchIfMissing=true |
| **P1-7** | BufferRecoveryScheduler | `scheduler/BufferRecoveryScheduler.java:82` | Duplicate retry processing | @Locked distributed lock |
| **P1-9** | OutboxScheduler | `scheduler/OutboxScheduler.java:42` | Duplicate outbox processing | Partitioned scheduling |
| **P1-15** | ExpectationWriteBackBuffer | `service/v4/buffer/ExpectationWriteBackBuffer.java:96` | Instance-local shutdown | Redis leader election |

**Impact:** Data inconsistency under concurrent multi-instance operations.

---

### 1.3 ThreadLocal Usage Analysis

**Detected ThreadLocal Patterns:**

```java
// MDC Context Propagation (Verified Safe)
module-app/src/main/java/maple/expectation/aop/context/SkipEquipmentL2CacheContext.java
module-infra/src/main/java/maple/expectation/infrastructure/aop/context/SkipEquipmentL2CacheContext.java

// TraceAspect (Instance-local logging context - Safe)
module-app/src/main/java/maple/expectation/aop/aspect/TraceAspect.java
```

**Status:** âœ… **ACCEPTABLE** - ThreadLocal usage is limited to MDC/logging context propagation via TaskDecorator, not business state.

**TaskDecorator Verification:**
```java
// ExecutorConfig.java:134-136
@Bean
public TaskDecorator contextPropagatingDecorator() {
    return taskDecoratorFactory().createContextPropagatingDecorator();
}
```

**Conclusion:** ThreadLocal usage is properly isolated and propagated across thread pools via TaskDecorator. No scale-out blockers identified.

---

## 2. Distributed Coordination

### 2.1 âœ… PASS: Redis-Based Distributed Locks

**Configuration:** `/home/maple/MapleExpectation/module-app/src/main/java/maple/expectation/config/RedissonConfig.java`

**Key Settings:**
```java
// Sentinel Mode (Production)
.setMasterConnectionPoolSize(64)
.setMasterConnectionMinimumIdleSize(24)
.setTimeout(8000) // 8s timeout (Issue #225)
.setConnectTimeout(5000)

// Single Server Mode (Development)
.setConnectionPoolSize(64)
.setConnectionMinimumIdleSize(24)
```

**Status:** âœ… **READY FOR SCALE-OUT**

**Assessment:**
- Connection pool sized for N=10+ instances
- Proper timeout hierarchy (Redis 8s > DB 5s)
- NAT mapping support for containerized deployments

---

### 2.2 âš ï¸ WARNING: Scheduler Distribution Gaps

**Schedulers WITHOUT Distributed Locks (P1 Blockers):**

| Scheduler | Issue | Risk |
|-----------|-------|------|
| `BufferRecoveryScheduler` | No @Locked annotation | Duplicate retry processing |
| `OutboxScheduler` | No @Locked annotation | Duplicate outbox processing |
| `LikeSyncScheduler` | Partial distribution (globalSync only) | Potential race conditions |

**Example - BufferRecoveryScheduler:**
```java
@Scheduled(fixedRateString = "${scheduler.buffer-recovery.retry-rate:5000}")
public void processRetryQueue() {
    // âŒ No @Locked - all instances execute simultaneously
}
```

**Fix Required:**
```java
@Locked(key = "buffer:recovery:retry")
@Scheduled(fixedRateString = "${scheduler.buffer-recovery.retry-rate:5000}")
public void processRetryQueue() {
    // âœ… Single leader instance executes
}
```

---

### 2.3 âœ… PASS: Redis Stream Consumer Groups

**Evidence:** `infrastructure/messaging/RedisStreamEventConsumer.java`

**Status:** âœ… **READY FOR SCALE-OUT**

**Features:**
- Consumer group partitioning supported
- Pending entries tracking
- Automatic ACK/NACK handling

**Note:** P0-7 (CompensationLogService) requires unique consumerId per instance to avoid group collision.

---

## 3. Thread Pool Sizing & Backpressure

### 3.1 âœ… EXCELLENT: Virtual Thread Adoption

**Configuration:** `application.yml`
```yaml
spring:
  threads:
    virtual:
      enabled: true
```

**Status:** âœ… **READY FOR SCALE-OUT**

**Benefits:**
- 10,000+ concurrent requests on single vCPU (vs. 200 platform threads)
- Automatic backpressure (blocking virtual thread doesn't consume OS thread)
- Reduced memory footprint (~1KB per virtual thread vs. 1MB platform thread)

---

### 3.2 âœ… EXCELLENT: Dedicated Thread Pool Configuration

**Executors Analysis:**

| Executor | Core | Max | Queue | Policy | Scale-Out Ready |
|----------|------|-----|-------|--------|-----------------|
| `equipmentProcessingExecutor` | 8 | 16 | 200 | AbortPolicy | âœ… Yes |
| `presetCalculationExecutor` | 12 | 24 | 100 | AbortPolicy | âœ… Yes |
| `expectationComputeExecutor` | 4 | 8 | 200 | AbortPolicy | âœ… Yes |
| `alertTaskExecutor` | 2 | 4 | 200 | AbortPolicy | âœ… Yes |
| `aiTaskExecutor` | Virtual | Semaphore(10) | âˆ | AbortPolicy | âœ… Yes |
| `taskScheduler` | 3 | - | - | AbortPolicy | âœ… Yes |

**Key Files:**
- `/home/maple/MapleExpectation/module-app/src/main/java/maple/expectation/config/ExecutorConfig.java`
- `/home/maple/MapleExpectation/module-app/src/main/java/maple/expectation/config/EquipmentProcessingExecutorConfig.java`
- `/home/maple/MapleExpectation/module-app/src/main/java/maple/expectation/config/PresetCalculationExecutorConfig.java`
- `/home/maple/MapleExpectation/module-app/src/main/java/maple/expectation/config/SchedulerConfig.java`

**Status:** âœ… **READY FOR SCALE-OUT**

**Highlights:**
1. **AbortPolicy** uniformly applied (no CallerRunsPolicy backpressure loss)
2. **TaskDecorator** for MDC propagation across async boundaries
3. **Micrometer metrics** for all executors (monitoring visibility)
4. **Graceful shutdown** configured (30-60s wait for completion)

---

### 3.3 âš ï¸ WARNING: Thread Pool Contention Risk

**Issue:** P1-8 (LikeSyncScheduler) - Potential thread pool starvation

```java
@Scheduled(fixedRate = 1000)
public void localFlush() { }  // All instances execute

@Scheduled(fixedRate = 3000)
public void globalSyncCount() { }  // PartitionedFlushStrategy (safe)

@Scheduled(fixedRate = 3000)
public void globalSyncRelation() { }  // Same 3s interval - potential collision
```

**Risk:** With N=10 instances, `localFlush` executes 10Ã—/second â†’ `equipmentProcessingExecutor` saturation.

**Recommendation:** Distribute `localFlush` via hash-based partitioning or leader election.

---

## 4. Connection Pooling

### 4.1 âœ… GOOD: MySQL HikariCP Configuration

**Production Settings:** `application-prod.yml`
```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 50
      connection-timeout: 3000
      leak-detection-threshold: 60000
      connection-init-sql: "SET SESSION lock_wait_timeout = 8"
```

**Dedicated Lock Pool:** `LockHikariConfig.java`
```java
// Fixed pool size (Min=Max) to eliminate handshake overhead
config.setMaximumPoolSize(poolSize); // 40 (default) / 150 (prod)
config.setMinimumIdle(poolSize);
config.setConnectionTimeout(5000);
config.setPoolName("MySQLLockPool");
```

**Status:** âœ… **READY FOR SCALE-OUT**

**Assessment:**
- Main pool: 50 connections â†’ Supports ~235 RPS (Little's Law: 235 Ã— 0.2s = 47)
- Lock pool: 150 connections â†’ Redis fallback capacity
- Connection timeout: 3s (fail-fast)
- Leak detection: 60s (early warning)

---

### 4.2 âœ… GOOD: Redis Connection Pooling

**Redisson Configuration:** `RedissonConfig.java`
```java
// Sentinel Mode
.setMasterConnectionPoolSize(64)
.setMasterConnectionMinimumIdleSize(24)

// Single Server Mode
.setConnectionPoolSize(64)
.setConnectionMinimumIdleSize(24)
```

**Status:** âœ… **READY FOR SCALE-OUT**

**Capacity Analysis:**
- 64 connections Ã— 10 instances = 640 total Redis connections
- Redis maxclients default: 10,000 â†’ 15Ã— headroom
- Connection reuse via connection pool (no per-request overhead)

---

### 4.3 âš ï¸ WARNING: Connection Pool Exhaustion Scenarios

**Risk:** P0-8 (DynamicTTLManager) - All instances execute TTL SCAN simultaneously

```java
@Async
@EventListener
public void onMySQLDown(MySQLDownEvent event) {
    // All instances trigger SCAN â†’ Redis connection spike
    RLock lock = redissonClient.getLock(properties.getTtlLockKey());
    // ...
}
```

**Impact:** N instances Ã— 64 connections = potential Redis connection exhaustion.

**Fix Required:** Leader election pattern - single instance executes TTL adjustments.

---

## 5. Graceful Shutdown & Data Persistence

### 5.1 âš ï¸ WARNING: Instance-Local Shutdown Coordination

**Components with Instance-Local Shutdown State:**

| Component | State Type | Issue | Fix Required |
|-----------|------------|-------|--------------|
| `ExpectationWriteBackBuffer` | `volatile boolean shuttingDown` | Instance-local flag | Redis shutdown key |
| `GracefulShutdownCoordinator` | `volatile boolean running` | Lifecycle state not distributed | Redis lifecycle key |
| `LoggingAspect` | `volatile boolean running` | SmartLifecycle not coordinated | K8s readiness probe |

**Example - ExpectationWriteBackBuffer:**
```java
// Line 96
private volatile boolean shuttingDown = false;

// Issue: Each instance sets this independently
// Rolling update: Instance A shuts down while B still active
// â†’ Data loss if A has unflushed buffer data
```

**Fix Required:**
```java
// Redis-based shutdown coordination
private boolean isShuttingDown() {
    return redissonClient.getBucket("system:shutdown:" + instanceId).isExists();
}
```

---

### 5.2 âœ… PASS: Graceful Shutdown Configuration

**application.yml:**
```yaml
spring:
  lifecycle:
    timeout-per-shutdown-phase: 50s
```

**Status:** âœ… **READY FOR SCALE-OUT**

**Verification:**
- 50s timeout accommodates:
  - Equipment write-back (30s await termination)
  - Redis sync (10s)
  - Scheduler drain (10s)
- SmartLifecycle beans properly ordered

---

### 5.3 âš ï¸ WARNING: Phaser-Based In-Flight Tracking

**Component:** `ExpectationWriteBackBuffer.java:70-77`

```java
private final Phaser shutdownPhaser = new Phaser() {
    @Override
    protected boolean onAdvance(int phase, int parties) {
        return parties == 0;
    }
};
```

**Issue:** Phaser tracks in-flight offers **per instance only**. Distributed shutdown coordination requires Redis pending count.

**Assessment:** âœ… **ACCEPTABLE** for current single-instance deployment. âš ï¸ **BLOCKER** for N-instance scale-out.

---

## 6. Error Handling & Circuit Breakers

### 6.1 âœ… PASS: Global Exception Handling

**File:** `error/GlobalExceptionHandler.java`

**Status:** âœ… **READY FOR SCALE-OUT**

**Features:**
- `@RestControllerAdvice` - Centralized error handling
- Circuit breaker exceptions â†’ 503 + Retry-After header
- RejectedExecutionException â†’ 503 + Retry-After 60s (Issue #168)
- CompletionException unwrapping â†’ Proper cause propagation

---

### 6.2 âœ… PASS: Resilience4j Configuration

**application.yml:**
```yaml
resilience4j:
  circuitbreaker:
    circuit-breaker-aspect-order: 400
```

**Status:** âœ… **READY FOR SCALE-OUT**

**Verification:**
- Circuit breaker state maintained locally (acceptable)
- Metrics exported to Prometheus for cluster-wide aggregation
- No shared circuit breaker state across instances (by design)

---

## 7. Cache Invalidation Strategy

### 7.1 âœ… PASS: Redis Pub/Sub Cache Invalidation

**Files:**
- `infrastructure/cache/invalidation/impl/RedisCacheInvalidationPublisher.java`
- `infrastructure/cache/invalidation/impl/RedisCacheInvalidationSubscriber.java`

**Status:** âœ… **READY FOR SCALE-OUT**

**Features:**
- Pub/sub pattern for cluster-wide invalidation
- Instance-local L1 cache (Caffeine) + distributed L2 (Redis)
- TieredCache for automatic L1/L2 coordination

---

## 8. Metrics & Monitoring

### 8.1 âœ… PASS: Prometheus Metrics Export

**application.yml:**
```yaml
management:
  endpoints:
    web:
      exposure:
        include: "health,info,metrics,prometheus"
  metrics:
    tags:
      application: ${spring.application.name}
    export:
      prometheus:
        enabled: true
```

**Status:** âœ… **READY FOR SCALE-OUT**

**Executor Metrics Verification:**
```java
// EquipmentProcessingExecutorConfig.java:113-115
new ExecutorServiceMetrics(
    executor.getThreadPoolExecutor(),
    "equipment.processing",
    Collections.emptyList()
).bindTo(meterRegistry);
```

**Metrics Available:**
- `executor.completed` - Completed tasks
- `executor.active` - Active threads
- `executor.queued` - Queue size
- `executor.rejected` - Rejected tasks (AbortPolicy)

---

## 9. Recommendations

### 9.1 Immediate Actions (Before Scale-Out)

**Sprint 1 - Feature Flag Defaults (Low Risk, Week 1)**
1. Set `app.buffer.redis.enabled=true` as default (P0-2, P0-3)
2. Set `matchIfMissing=true` for Redis-based components (P1-4, P1-5)
3. Convert `AiSreService` to Bean with semaphore limiting (P0-5)
4. Add validation tests to prevent In-Memory mode in production

**Sprint 2 - In-Memory â†’ Redis Migration (Medium Risk, Week 2-3)**
1. `AlertThrottler` â†’ Redis AtomicLong (P0-1)
2. `SingleFlightExecutor` â†’ Redis distributed single-flight (P0-4)
3. `LoggingAspect.running` â†’ Redis shutdown flag (P0-6)
4. Add integration tests with 2+ Docker containers

**Sprint 3 - Scheduler Distribution (High Risk, Week 3-4)**
1. Add `@Locked` to `BufferRecoveryScheduler` (P1-7)
2. Add `@Locked` to `OutboxScheduler` (P1-9)
3. Fix `LikeSyncScheduler` globalSync collision (P1-8)
4. Implement leader election for `DynamicTTLManager` (P0-8)
5. Chaos testing with 5+ instances

---

### 9.2 Scale-Out Deployment Strategy

**Phase 1: Dual-Instance Validation (1 Week)**
- Deploy 2 instances behind load balancer
- Monitor:
  - AlertThrottler daily count (should NOT double)
  - Single-flight effectiveness (API call count)
  - Scheduler duplicate execution (logs)
  - Graceful shutdown data loss

**Phase 2: Gradual Scale-Out (2 Weeks)**
- 2 â†’ 3 â†’ 5 instances
- Validate metrics scale linearly
- Verify no connection pool exhaustion
- Test rolling update safety

**Phase 3: Production N-Instance (Ongoing)**
- Auto-scaling based on RPS/CPU
- HPA (K8s) or ASG (AWS) integration
- Continuous chaos testing

---

### 9.3 Monitoring & Alerting

**Critical Metrics for Scale-Out:**

| Metric | Alert Threshold | Indicates |
|--------|----------------|-----------|
| `expectation.buffer.pending` | > 8000 (80% capacity) | Buffer saturation |
| `executor.rejected{name=equipment.processing}` | > 0 | Thread pool exhaustion |
| `ai.throttle.daily.count` | > 50 (quota breach) | P0-1 data inconsistency |
| `scheduler.rejected` | > 0 | Scheduler deadlock |
| `hikari.connections.active` | > 45 (90% pool) | DB connection exhaustion |
| `redisson.connection.active` | > 55 (85% pool) | Redis connection exhaustion |

---

## 10. Conclusion

### Current Readiness Score

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCALE-OUT READINESS: 70/100                        â”‚
â”‚                                                     â”‚
â”‚  âœ… Stateless Sessions:        10/10               â”‚
â”‚  âœ… Thread Pool Sizing:        9/10  (-1: P1-8)   â”‚
â”‚  âœ… Connection Pooling:        8/10  (-2: P0-8)   â”‚
â”‚  âš ï¸  Distributed Coordination: 7/10  (-3: P0s)   â”‚
â”‚  âœ… Graceful Shutdown:         7/10  (-3: P1s)   â”‚
â”‚  âš ï¸  In-Memory State:          6/10  (-4: 22 items)â”‚
â”‚  âœ… Error Handling:            10/10               â”‚
â”‚  âœ… Monitoring:                9/10  (-1: aggregation)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Final Verdict

**STATUS:** âš ï¸ **CONDITIONAL READY**

**Can Scale to N Instances:** âœ… **YES**, after P0 blocker resolution

**Estimated Time to Full Readiness:** 3-4 weeks (3 sprints)

**Critical Success Factors:**
1. Resolve 8 P0 In-Memory state blockers
2. Add distributed locks to 3 schedulers
3. Implement Redis-based shutdown coordination
4. Validate with 2+ instance chaos tests

**Risk Level:**
- Current (1 instance): ğŸŸ¢ **LOW** - Production safe
- With P0 fixes (N instances): ğŸŸ¡ **MEDIUM** - Manageable risk
- Without P0 fixes (N instances): ğŸ”´ **HIGH** - Data integrity risks

---

## Appendix A: Verification Commands

```bash
# 1. Check In-Memory state patterns
grep -r "new ConcurrentHashMap\|new AtomicInteger\|volatile.*=" src/main/java/ | wc -l

# 2. Verify Feature Flag defaults
grep -r "matchIfMissing.*false" src/main/java/

# 3. Check Scheduler methods without @Locked
grep -B5 "@Scheduled" src/main/java/ | grep -B1 "void " | grep -v "@Locked"

# 4. Test scale-out behavior
docker-compose up -d --scale app=2
docker-compose logs app | grep "Scheduled task executed"

# 5. Verify Redis distributed locks
redis-cli --scan --pattern "*:lock:*" | wc -l
```

---

## Appendix B: Evidence Trail

All claims in this report are supported by source code evidence:

| Claim | Evidence ID | Source Location |
|-------|-------------|-----------------|
| AlertThrottler In-Memory state | EVIDENCE-S001 | `monitoring/throttle/AlertThrottler.java:33` |
| LikeBufferStorage Caffeine cache | EVIDENCE-S003 | `service/v2/cache/LikeBufferStorage.java:35` |
| AiSreService unbounded executor | EVIDENCE-S006 | `monitoring/ai/AiSreService.java:65` |
| Scheduler without @Locked | EVIDENCE-S012 | `scheduler/BufferRecoveryScheduler.java:82` |
| ExpectationWriteBackBuffer volatile flag | EVIDENCE-S017 | `service/v4/buffer/ExpectationWriteBackBuffer.java:96` |

Full evidence catalog available in `/docs/04_Reports/04_09_Scale_Out/scale-out-blockers-analysis.md`.

---

*Report Generated: 2026-02-16*
*Next Review: After P0 blocker resolution*
*Analysis Method: Static code analysis + configuration audit + architecture assessment*
